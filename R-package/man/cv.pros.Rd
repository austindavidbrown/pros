% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pros.R
\name{cv.pros}
\alias{cv.pros}
\title{Cross-validation}
\usage{
cv.pros(X, y, K_fold = 10, alpha = c(1, 0, 0, 0, 0, 0),
  lambdas = c(), step_size, algorithm = "proximal_gradient_cd",
  max_iter = 10000, tolerance = 10^(-8), random_seed = 0)
}
\arguments{
\item{X}{is an \eqn{n \times m}-dimensional matrix of the data.}

\item{y}{is an \eqn{n \times m}-dimensional matrix of the data.}

\item{K_fold}{is the number of folds in cross-validation.}

\item{alpha}{is a \eqn{6}-dimensional vector of the convex combination corresponding to the penalization:
\itemize{
  \item \eqn{\alpha_1} is the \eqn{l^1} penalty.
  \item \eqn{\alpha_2} is the \eqn{l^2} penalty.
  \item \eqn{\alpha_3} is the \eqn{l^4} penalty.
  \item \eqn{\alpha_4} is the \eqn{l^6} penalty.
  \item \eqn{\alpha_5} is the \eqn{l^8} penalty.
  \item \eqn{\alpha_6} is the \eqn{l^{10}} penalty.
}}

\item{lambdas}{is a vector of dual penalization values to be evaluated.}

\item{step_size}{is a tuning parameter defining the step size. Larger values are more aggressive and smaller values are less aggressive.}

\item{algorithm}{is the optimization algorithm 
\itemize{
  \item \code{proximal_gradient_cd} uses proximal gradient coordinate descent.
  \item \code{subgradient_cd} uses subgradient coordinate descent.
}}

\item{max_iter}{is the maximum iterations the algorithm will run regardless of convergence.}

\item{tolerance}{is the accuracy of the stopping criterion.}

\item{random_seed}{is the random seed used in the algorithms.}
}
\value{
A class \code{cv_pros}
}
\description{
The \code{cv.pros} function is used for K-fold cross-validation.
}
