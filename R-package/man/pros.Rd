% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pros.R
\name{pros}
\alias{pros}
\title{Pros}
\usage{
pros(X, y, alpha = c(1, 0, 0, 0, 0, 0), lambda, step_size,
  algorithm = "proximal_gradient_cd", max_iter = 10000,
  tolerance = 10^(-8), random_seed = 0)
}
\arguments{
\item{X}{is an \eqn{n \times m}-dimensional matrix of the data.}

\item{y}{is an \eqn{n \times m}-dimensional matrix of the data.}

\item{alpha}{is a \eqn{6}-dimensional vector of the convex combination corresponding to the penalization:
\itemize{
  \item \eqn{\alpha_1} is the \eqn{l^1} penalty.
  \item \eqn{\alpha_2} is the \eqn{l^2} penalty.
  \item \eqn{\alpha_3} is the \eqn{l^4} penalty.
  \item \eqn{\alpha_4} is the \eqn{l^6} penalty.
  \item \eqn{\alpha_5} is the \eqn{l^8} penalty.
  \item \eqn{\alpha_6} is the \eqn{l^{10}} penalty.
}}

\item{lambda}{is the Lagrangian dual penalization parameter.}

\item{step_size}{is a tuning parameter defining the step size. Larger values are more aggressive and smaller values are less aggressive.}

\item{algorithm}{is the optimization algorithm 
\itemize{
  \item \code{proximal_gradient_cd} uses proximal gradient coordinate descent.
  \item \code{subgradient_cd} uses subgradient coordinate descent.
}}

\item{max_iter}{is the maximum iterations the algorithm will run regardless of convergence.}

\item{tolerance}{is the accuracy of the stopping criterion.}

\item{random_seed}{is the random seed used in the algorithms.}
}
\value{
A class \code{pros}
}
\description{
The \code{pros} function is used to fit a single regression model with a specified penalization.
}
\examples{
n = 1000
X1 <- rnorm(n)
X2 <- rnorm(n)
y = 3 + 5 * X1 + 0 * X2
X = matrix(c(X1, X2), ncol = 2)
fit = pros(X, y, lambda = 2, step_size = .001)
predict(fit, X)

}
\references{
Zou, Hui. “Regularization and variable selection via the elastic net.” (2004).
}
